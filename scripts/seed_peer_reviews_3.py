#!/usr/bin/env python3
"""Seed peer reviews for papers 57-84."""
from __future__ import annotations

import sys
from pathlib import Path

sys.path.insert(0, str(Path(__file__).resolve().parent.parent))
from app.db import get_admin_client

REVIEWS = {
    57: """STRENGTHS:
RoboGen is one of the first convincing demonstrations that LLMs can serve as an autonomous curriculum designer for robot learning. The pipeline is genuinely end-to-end: the LLM proposes tasks, generates reward functions, creates training environments in simulation, and orchestrates a curriculum of increasing difficulty. The approach dramatically reduces the human engineering bottleneck — no manual reward shaping, no hand-designed task progressions. The diversity of tasks the system can generate (grasping, articulated object manipulation, locomotion) is impressive and suggests real scalability. The automated curriculum means the agent encounters tasks at the frontier of its ability, which is a well-established principle from developmental learning.

LIMITATIONS:
The generated tasks are constrained to what the LLM can describe in terms of existing simulation primitives — truly novel manipulation strategies that require new physics or contact-rich reasoning are out of reach. The reward functions generated by the LLM are often sparse or poorly shaped, leading to high variance in training outcomes; the paper somewhat glosses over the failure rate of generated rewards. The reliance on a fixed set of simulation assets (SAPIEN, etc.) limits the visual and physical diversity of training environments. There is no sim-to-real transfer demonstrated — everything stays in simulation, which is a major gap for a paper about robot learning. The curriculum ordering heuristic is simple and does not adapt based on the agent's actual learning progress.

COMMUNITY RECEPTION:
The community received RoboGen with enthusiasm as a creative application of LLMs to the robotics pipeline, particularly for its ambition in closing the loop from task generation to policy learning. However, reviewers and follow-up discussions noted that the lack of real-world validation is a significant weakness. The work is seen as a strong proof-of-concept but not yet a practical system. It influenced subsequent work on LLM-driven reward design (e.g., Eureka) and automated environment generation. Some researchers expressed concern about the LLM hallucinating physically implausible tasks.

OPEN QUESTIONS:
Can the generated curricula actually match or exceed human-designed curricula for complex dexterous manipulation? How do you verify that LLM-generated rewards are actually aligned with intended task semantics without human inspection? What happens when the LLM's world model diverges from actual physics — can we detect and recover from hallucinated task specifications? Is there a principled way to select which generated tasks are most useful for downstream transfer?""",

    58: """STRENGTHS:
Eureka represents a breakthrough in automated reward design by using LLMs (GPT-4) to write reward functions as executable code, then using evolutionary search over reward candidates to find high-performing ones. The results are striking: Eureka-designed rewards match or exceed human expert rewards on 83% of tasks, including enabling a Shadow Hand to perform pen spinning — a dexterous task that had resisted prior automated approaches. The key insight of treating reward design as a code generation problem (rather than parameter optimization) is powerful because it leverages the LLM's understanding of task semantics. The evolutionary mutation strategy, where the LLM reflects on training curves to propose reward improvements, is an elegant closed-loop design.

LIMITATIONS:
Eureka requires extensive GPU compute for the evolutionary search — each reward candidate must be trained to convergence, and multiple generations are needed, making the total compute cost very high (thousands of GPU-hours for complex tasks). The approach is demonstrated exclusively in IsaacGym simulation with no sim-to-real transfer. The LLM-generated rewards can be brittle: small changes in environment parameters sometimes require re-running the full search. The method assumes access to a well-defined state space that the LLM can reason about, which may not hold for high-dimensional sensory inputs. The evolutionary search has no convergence guarantees and can get stuck in local optima of reward space.

COMMUNITY RECEPTION:
Eureka was widely celebrated in the robotics and RL communities, particularly for the pen-spinning demo which became iconic. NVIDIA's involvement gave it high visibility. Researchers appreciated the principled approach to a long-standing problem (reward design) and the strong empirical results. Critics pointed out that the compute requirements make it impractical for labs without massive GPU clusters, and that the lack of real-world validation is a recurring theme in this line of work. The paper directly inspired DrEureka and other LLM-based reward design systems. Some RL theorists noted that the approach sidesteps fundamental questions about reward specification and alignment.

OPEN QUESTIONS:
Can Eureka-style reward search be made sample-efficient enough for real-world training loops? How do we ensure that evolved rewards don't exploit simulator bugs or physics artifacts? Can the approach handle tasks where success is hard to define programmatically (e.g., "make the object look neat")? Is there a theoretical characterization of which tasks are amenable to LLM-based reward design versus requiring human specification?""",

    59: """STRENGTHS:
DrEureka directly addresses the sim-to-real gap that was missing from Eureka by using LLMs to co-optimize reward functions and domain randomization parameters. This is a meaningful advance: instead of just designing rewards in simulation, the system explicitly reasons about what physical parameters need randomization to enable transfer. The LLM generates both the reward code and the randomization ranges, creating a unified pipeline from task description to real-robot deployment. The demonstration on quadruped locomotion and dexterous manipulation tasks with actual sim-to-real transfer is convincing and fills a critical gap in the Eureka line of work.

LIMITATIONS:
The domain randomization parameter space is still manually defined — the LLM selects ranges within a human-specified set of randomizable parameters, rather than discovering what to randomize. The real-world experiments are limited in scope: relatively few tasks and environments, with controlled conditions. The LLM's reasoning about physics and sim-to-real gaps is necessarily superficial — it cannot truly understand contact dynamics or material properties from text descriptions alone. The method still requires significant simulation compute, and there is no systematic comparison against well-tuned manual domain randomization baselines by domain experts. The approach assumes that domain randomization is the right strategy for sim-to-real transfer, ignoring alternatives like system identification or adaptation.

COMMUNITY RECEPTION:
DrEureka was well-received as a natural and necessary extension of Eureka, with the community appreciating that it actually closes the sim-to-real loop. The quadruped locomotion demos were particularly compelling. However, some researchers noted that the sim-to-real results, while promising, are on tasks where domain randomization is known to work well — the harder question is whether LLM-guided randomization helps on tasks where sim-to-real transfer is genuinely difficult. The work stimulated broader discussion about whether LLMs can serve as a general-purpose "intuition engine" for robotics engineering decisions.

OPEN QUESTIONS:
Can the LLM identify when domain randomization is insufficient and suggest alternative transfer strategies? How sensitive are the results to the quality of the physics simulator? Can this approach scale to contact-rich manipulation where the sim-to-real gap is much larger? What happens when the LLM's prior about physical parameters is wrong — does the system fail gracefully?""",

    60: """STRENGTHS:
TRANSIC offers a thoughtful approach to sim-to-real transfer by using language as a grounding medium between simulation and reality. Rather than relying purely on domain randomization or system identification, TRANSIC uses language descriptions to bridge the semantic gap between simulated and real observations. The key insight — that language provides a domain-invariant representation that abstracts away visual and physical differences — is well-motivated and connects to broader ideas in representation learning. The framework decomposes the transfer problem into components that can be individually addressed through language grounding, which is modular and interpretable.

LIMITATIONS:
The language grounding approach works best for tasks where semantic descriptions capture the relevant state information, but many manipulation tasks depend on precise geometric and force information that language cannot easily express. The reliance on a vision-language model to provide the grounding introduces its own sim-to-real gap (VLMs may describe simulated and real scenes differently). The experimental evaluation is limited to a small number of manipulation tasks, and it is unclear how the approach handles tasks requiring fine-grained physical reasoning. The method adds significant complexity compared to simpler domain randomization baselines, and the paper does not convincingly demonstrate when this complexity is justified.

COMMUNITY RECEPTION:
TRANSIC received interest for its novel framing of sim-to-real transfer through language, which resonated with the growing trend of language-grounded robotics. The community appreciated the conceptual clarity but raised questions about scalability and generality. Some researchers viewed it as over-engineered for the tasks demonstrated — domain randomization alone might achieve comparable results. Others saw it as an important step toward more structured and interpretable transfer methods. The work contributed to the broader conversation about the role of language in bridging the reality gap.

OPEN QUESTIONS:
For which task categories does language grounding genuinely outperform domain randomization for sim-to-real transfer? Can the approach handle deformable objects or fluid manipulation where state descriptions are inherently ambiguous? How does the quality of the underlying VLM affect transfer success? Is there a way to automatically determine when language grounding is needed versus when simpler transfer methods suffice?""",

    61: """STRENGTHS:
PLD (Post-training with RL for self-improving VLAs) addresses a critical gap in the VLA pipeline: how to improve pre-trained vision-language-action models through online interaction rather than just scaling up demonstrations. The use of reinforcement learning as a post-training stage is well-motivated — it allows the policy to refine behaviors beyond what is captured in the demonstration data and potentially discover more efficient strategies. The self-improving aspect, where the model iteratively collects data and fine-tunes, connects to important ideas about autonomous improvement. The framework is general enough to be applied to different VLA backbones.

LIMITATIONS:
RL fine-tuning of large VLA models is extremely sample-inefficient in the real world, and the paper relies heavily on simulation for the RL phase, which reintroduces sim-to-real concerns. The reward functions used for RL post-training are task-specific and require engineering, partially undermining the generality of the VLA approach. There is a risk of catastrophic forgetting during RL fine-tuning — the model may lose capabilities on tasks not included in the RL phase. The paper does not thoroughly investigate the stability of training or how sensitive results are to RL hyperparameters. The improvement margins over pure imitation learning baselines are sometimes modest.

COMMUNITY RECEPTION:
The community recognized PLD as tackling an important problem — moving beyond pure imitation learning for VLAs. Researchers working on both foundation models and RL appreciated the synthesis. However, some questioned whether the RL gains justify the additional engineering complexity, especially given the modest improvements on some tasks. The work contributed to growing interest in "post-training" for robotics models, analogous to RLHF for language models. There was active debate about whether online RL or offline RL is the right post-training paradigm for VLAs.

OPEN QUESTIONS:
Can RL post-training be made stable enough to improve VLAs without catastrophic forgetting? What is the right reward signal for general-purpose RL fine-tuning of VLAs? How many RL interactions are needed to see meaningful improvement over the pre-trained policy? Is there an equivalent of RLHF for robotics — where human preferences rather than engineered rewards guide post-training?""",

    62: """STRENGTHS:
Sparsh from Meta is a significant step toward foundation models for tactile sensing, addressing the long-standing fragmentation in tactile perception where each sensor type has its own bespoke processing pipeline. The model is trained on a large-scale tactile dataset spanning multiple sensor modalities (GelSight, DIGIT, etc.) and demonstrates transfer across sensor types. The self-supervised pre-training approach (using masked autoencoding and contrastive learning on tactile images) is well-designed and produces representations that are useful across downstream tasks like slip detection, texture classification, and grasp stability prediction. The scale of data collection and the multi-sensor evaluation are commendable.

LIMITATIONS:
The "foundation model" claim is premature — Sparsh is trained on a limited number of sensor types and tasks, and it is unclear whether the learned representations truly generalize to novel sensors or manipulation scenarios not seen during pre-training. The tactile data is primarily from vision-based tactile sensors (which produce images), and the approach may not transfer to other tactile modalities like resistive arrays or capacitive skins. The downstream task evaluations are relatively simple and do not test the model on complex, contact-rich manipulation where tactile sensing matters most. The model does not integrate tactile information with vision or proprioception, which limits its utility for real manipulation systems.

COMMUNITY RECEPTION:
Sparsh was welcomed by the tactile sensing community as a much-needed effort to standardize and scale tactile representations. Researchers appreciated Meta's investment in data collection and the open-sourcing of models. However, the broader robotics community questioned whether tactile foundation models are the right abstraction — some argued that tactile sensing is too task-specific and hardware-dependent for a one-size-fits-all model. The work catalyzed discussion about what "foundation model" means in the context of sensing modalities that are far less standardized than vision or language.

OPEN QUESTIONS:
Can a single tactile foundation model truly serve sensors with fundamentally different physical principles (optical vs. resistive vs. capacitive)? How should tactile representations be fused with visual and proprioceptive information in a unified model? What scale of tactile data is actually needed for useful generalization? Are self-supervised objectives sufficient, or is task-specific supervision necessary for contact-rich manipulation?""",

    63: """STRENGTHS:
UniT proposes a unified representation for tactile perception that works across different tactile sensor types, which is an important goal for making tactile sensing more accessible in robotics. The architecture uses a shared encoder that maps diverse tactile inputs into a common embedding space, enabling knowledge transfer between sensors and reducing the need for sensor-specific models. The evaluation spans multiple sensor types and tasks, demonstrating that the unified representation can match or approach sensor-specific baselines. The work is clearly motivated by the practical challenge of sensor heterogeneity in the tactile domain.

LIMITATIONS:
The unification is primarily across vision-based tactile sensors that share similar image-like output formats, which makes the "unified" claim somewhat narrow. The representational alignment across sensors is achieved through paired data collection, which is expensive and may not scale to new sensor types easily. The downstream task performance sometimes lags behind sensor-specific models, suggesting that the unified representation trades off task performance for generality. The evaluation tasks (texture recognition, hardness estimation) are simpler than the contact-rich manipulation scenarios where tactile sensing is most critical. There is limited analysis of what information is lost in the unification process.

COMMUNITY RECEPTION:
UniT received positive attention from the tactile sensing community as a step toward standardization. Researchers appreciated the systematic evaluation across sensor types. However, some noted that the practical impact is limited since most labs use a single sensor type and would prefer optimized sensor-specific models. The work was seen as complementary to Sparsh, with both contributing to the broader goal of tactile foundation models. There was debate about whether representation unification is the right approach versus developing better sensor-agnostic features.

OPEN QUESTIONS:
Can unified tactile representations be extended to non-vision-based tactile sensors without losing critical modality-specific information? What is the minimum paired data needed for effective cross-sensor alignment? How does the unified representation perform on dexterous manipulation tasks requiring precise force control? Is there a principled way to determine when a sensor-specific model is needed versus when the unified representation suffices?""",

    64: """STRENGTHS:
T3 (Touch-Text-Tactile) introduces an interesting cross-modal framework connecting tactile sensing with language, enabling tasks like tactile-to-text description and text-guided tactile understanding. The approach of aligning tactile representations with language embeddings opens up new interaction paradigms — a robot could describe what it feels or be instructed to find objects by touch-based descriptions. The training methodology, using contrastive learning between tactile and text modalities, is well-motivated by the success of CLIP-style alignment in vision-language. The dataset curation effort, pairing tactile readings with natural language descriptions, is a valuable contribution.

LIMITATIONS:
The language descriptions of tactile experiences are inherently limited — human vocabulary for describing touch is far less rich than for vision, which constrains the alignment quality. The tactile data is again primarily from vision-based sensors, and the text descriptions may be biased toward visual features of the tactile images rather than true physical properties. The evaluation is mostly on classification and retrieval tasks rather than demonstrating utility in actual manipulation pipelines. The model struggles with fine-grained tactile distinctions that are important for manipulation (e.g., distinguishing between similar textures that require different grasp forces). Scalability of the paired tactile-text dataset is a bottleneck.

COMMUNITY RECEPTION:
T3 was viewed as a creative and novel contribution to the growing field of multimodal tactile learning. The community was intrigued by the language-tactile alignment concept, though some questioned the practical utility — when would a robot need to describe what it feels in natural language? The work was more appreciated by the representation learning community than by manipulation researchers. It contributed to the broader narrative of connecting all sensing modalities through language as a common interface.

OPEN QUESTIONS:
Can language-aligned tactile representations actually improve manipulation performance, or is this primarily useful for human-robot communication? How do we handle the inherent ambiguity in language descriptions of touch? Can the approach generalize to tactile properties that are difficult to verbalize (e.g., complex friction patterns)? What is the right granularity of language for describing tactile experiences?""",

    65: """STRENGTHS:
ForceVLA represents an important architectural contribution by integrating force and tactile sensing directly into the vision-language-action model framework. Most VLAs are vision-only, which fundamentally limits their applicability to contact-rich manipulation tasks. ForceVLA demonstrates that adding force/torque and tactile modalities to the VLA architecture can improve performance on tasks like insertion, assembly, and delicate object handling where visual information alone is insufficient. The multimodal fusion approach is well-designed, with attention mechanisms that learn to weight different modalities based on task context.

LIMITATIONS:
The force/tactile integration adds significant complexity to the architecture and training pipeline, and the paper does not thoroughly analyze whether simpler approaches (e.g., reactive force controllers combined with a vision-only VLA) could achieve similar results with less complexity. The training data requirements increase substantially with the additional modalities — collecting demonstrations with synchronized force/tactile data is harder than vision-only. The model is evaluated on a limited set of tasks specifically chosen to require force information, which biases the evaluation. Generalization to tasks where force sensing is less critical is not well-studied, and there may be negative transfer.

COMMUNITY RECEPTION:
ForceVLA was recognized as addressing an important gap in the VLA literature. Researchers working on contact-rich manipulation were particularly supportive, arguing that force-blind VLAs are fundamentally limited for real-world deployment. However, the broader VLA community debated whether the multimodal complexity is worth it, especially given that many useful tasks can be solved with vision alone. The work stimulated discussion about what sensing modalities should be standard in future VLA architectures. Some researchers advocated for modular approaches where force control is handled separately from the VLA.

OPEN QUESTIONS:
What is the right architectural design for fusing force/tactile data with vision and language in VLAs? Can the force/tactile integration be made modality-agnostic so the same model works with or without force sensing? How much force/tactile training data is needed to see benefits over vision-only VLAs? For which task categories is force integration essential versus nice-to-have?""",

    66: """STRENGTHS:
SayCan is a landmark paper that elegantly addresses the grounding problem for LLMs in robotics. The key insight is brilliant in its simplicity: use the LLM's knowledge to propose actions (the "Say" part) and use learned affordance functions to filter for what is physically feasible (the "Can" part). By scoring each candidate action with both the LLM probability and a value function representing the probability of successful execution, SayCan produces plans that are both semantically meaningful and physically grounded. The real-robot experiments in a kitchen environment with a mobile manipulator are impressive and demonstrate genuine long-horizon task completion from natural language instructions.

LIMITATIONS:
The affordance grounding is brittle and relies heavily on a fixed library of pre-trained skills — SayCan cannot synthesize new behaviors or adapt existing skills to novel situations. If the required skill is not in the library, the system fails silently by selecting the closest available skill, which can lead to nonsensical behavior. The value functions used for affordance scoring require substantial real-world training data for each skill, which does not scale. The system handles novel objects poorly because the affordance functions are trained on a limited object set. The planning is greedy (one step at a time) with no lookahead, backtracking, or recovery from failures. The system assumes a static world and cannot handle dynamic environments or other agents.

COMMUNITY RECEPTION:
SayCan was highly influential and is widely cited as a foundational paper in LLM-based robot planning. Google's real-world demonstrations were compelling and captured broad attention. The "Say + Can" decomposition became a conceptual framework that many subsequent papers built upon. However, the robotics community quickly identified the scalability limitations — the skill library and affordance functions require too much manual engineering. Critics noted that the kitchen environment, while realistic-looking, was carefully controlled and far from truly open-world. The paper nonetheless opened the floodgates for LLM-planning research in robotics.

OPEN QUESTIONS:
How can the skill library be expanded autonomously without manual engineering of each new skill? Can affordance functions generalize to novel objects and scenes without retraining? Is the greedy planning strategy fundamentally limiting for tasks requiring complex reasoning or long-horizon planning? How should the system handle situations where no available skill achieves the desired effect?""",

    67: """STRENGTHS:
VIMA introduces a compelling multimodal prompting framework where robot manipulation tasks are specified through interleaved text and images. This is more expressive than pure text instructions — you can show the robot what you want rather than just telling it. The transformer-based architecture processes these multimodal prompts to directly output actions, enabling a single model to handle diverse task types (visual goal specification, one-shot imitation, constraint satisfaction). The VIMA-Bench benchmark provides a systematic evaluation of generalization across task types and difficulty levels. The architecture cleanly separates prompt understanding from action prediction.

LIMITATIONS:
VIMA is trained and evaluated entirely in a tabletop simulation environment with simple geometric objects, which limits the conclusions about real-world applicability. The multimodal prompts, while expressive, require careful engineering for each task type. The model struggles with tasks requiring precise spatial reasoning or long-horizon planning, as the transformer architecture does not explicitly model spatial relationships or temporal dependencies. The benchmark, while systematic, uses relatively simple manipulation primitives (pick-and-place) and does not capture the complexity of real-world manipulation. The model does not demonstrate significant zero-shot generalization to truly novel task types not seen during training.

COMMUNITY RECEPTION:
VIMA was well-received for its novel prompting paradigm and systematic benchmark. The community appreciated the idea that multimodal prompts could be more natural and informative than text-only instructions. However, the simulation-only evaluation was a significant limitation that reviewers consistently noted. Some researchers questioned whether the benchmark's task diversity is artificial — the underlying manipulation primitives are the same across tasks, just with different prompt types. The work influenced subsequent papers on multimodal robot interfaces but was somewhat overshadowed by concurrent work on VLAs that directly operate on real-world data.

OPEN QUESTIONS:
Can multimodal prompting scale to real-world manipulation with diverse objects and complex scenes? How do you handle ambiguous or underspecified prompts? What is the right balance between prompt expressiveness and task complexity? Can the approach be combined with real-world VLAs to get both multimodal prompting and physical grounding?""",

    68: """STRENGTHS:
This paper addresses a practical and important problem: how to distill the capabilities of large language-conditioned policies into smaller, deployable models. The key contribution is showing that language conditioning can serve as a structured knowledge transfer medium — the large model's understanding of language-task mappings can be compressed into a student model that retains much of the performance. The distillation framework is well-designed, with language serving as both the task specification and the alignment signal between teacher and student. The paper demonstrates that distilled policies can retain multi-task capabilities while being significantly smaller and faster at inference.

LIMITATIONS:
The distillation is bounded by the teacher model's capabilities — the student cannot exceed the teacher, and errors in the teacher's language grounding propagate to the student. The compression ratios achievable before significant performance degradation are not thoroughly characterized. The paper focuses on simulation experiments and does not address whether distillation preserves the subtle behaviors needed for real-world execution. Language conditioning, while useful for multi-task distillation, may not capture the fine-grained behavioral details needed for dexterous manipulation. The approach assumes a fixed task distribution and does not address how to update the distilled model when new tasks are added.

COMMUNITY RECEPTION:
The paper was appreciated for addressing the practical concern of deploying large models on resource-constrained robot hardware. The robotics community recognized that model size and inference speed matter enormously for real-time control. Researchers working on model compression and knowledge distillation found the language-conditioned framing to be a natural extension of their work. Some critics noted that the performance gaps between teacher and student, while acceptable for simple tasks, might be unacceptable for safety-critical or precision tasks. The work contributed to growing interest in efficient robot learning.

OPEN QUESTIONS:
What is the theoretical minimum model size for retaining language-conditioned multi-task capabilities? Can distillation preserve the long-tail behaviors that are important for robustness? How do you determine which tasks will suffer most from compression? Is progressive distillation (multiple rounds of compression) viable for robot policies?""",

    69: """STRENGTHS:
HumanPlus from Stanford demonstrates an impressive system for full-body humanoid robot control through real-time human shadowing and subsequent imitation learning. The approach of using low-cost RGB cameras to track human motion and retarget it to a humanoid robot in real-time is elegant and practical — it avoids expensive mocap systems while enabling intuitive teleoperation. The imitation learning pipeline that distills shadowed demonstrations into autonomous policies shows that humanoid robots can learn complex whole-body behaviors (walking while manipulating, crouching, reaching). The end-to-end system from human demonstration to autonomous execution is well-integrated.

LIMITATIONS:
The motion retargeting from human to humanoid is inherently imprecise due to kinematic differences between human and robot bodies — joint limits, link lengths, and mass distributions differ significantly, leading to retargeting artifacts. The system struggles with dynamic motions that require careful balance control, as the retargeting does not account for the robot's actual dynamics. The imitation learning component requires many demonstrations for each behavior and does not generalize well across tasks. The RGB-based tracking can be noisy and loses accuracy during fast motions or occlusions. The demonstrated tasks, while impressive visually, are relatively simple compared to what humanoid robots would need to do in practical settings.

COMMUNITY RECEPTION:
HumanPlus generated significant excitement, particularly for its accessible approach to humanoid teleoperation using commodity hardware. The video demos were compelling and widely shared. The humanoid robotics community saw it as a step toward scalable data collection for humanoid learning. However, researchers with experience in bipedal locomotion noted that the balance control during shadowing is not robust, and the system would fail on uneven terrain or with perturbations. Some questioned whether imitation learning from human shadowing is the right paradigm versus more structured control approaches. The work contributed to the growing humanoid hype cycle.

OPEN QUESTIONS:
How can motion retargeting be made dynamically consistent so the robot maintains balance during human shadowing? Can the approach scale to complex multi-step manipulation tasks, not just locomotion and simple reaching? What is the minimum number of demonstrations needed for reliable policy learning? How does the system handle the embodiment gap between human and robot for tasks requiring precise force control?""",

    70: """STRENGTHS:
TinyVLA addresses a critical practical concern: existing VLAs are too large and slow for real-time robotic control. The paper shows that through careful architectural design and training strategies, it is possible to create VLAs that are significantly smaller and faster while retaining much of the performance. The data efficiency improvements are particularly valuable — TinyVLA achieves competitive results with fewer demonstrations, which matters enormously in robotics where data collection is expensive. The architecture choices (efficient backbone, lightweight action head) are well-justified and demonstrate that not all components of large VLAs are necessary for good performance.

LIMITATIONS:
The performance-efficiency tradeoff is real — TinyVLA does sacrifice accuracy on the most complex tasks, particularly those requiring long-horizon reasoning or fine-grained manipulation. The paper primarily evaluates on relatively simple manipulation benchmarks where the full expressiveness of large VLAs is not needed, which may overstate the competitiveness of the small model. The claimed data efficiency gains may partly reflect the simplicity of the evaluation tasks rather than a genuine architectural advantage. The model's language understanding is notably weaker than larger VLAs, limiting its ability to follow complex or compositional instructions. There is limited analysis of failure modes and where the smaller model falls short.

COMMUNITY RECEPTION:
TinyVLA was well-received by the applied robotics community, which has long been frustrated by the impracticality of deploying billion-parameter models on robots. The efficiency gains were seen as a necessary step toward practical VLA deployment. Researchers appreciated the honest evaluation showing where smaller models struggle. However, some in the foundation model community argued that the right approach is to improve hardware and inference infrastructure rather than shrinking models. The work contributed to a growing subfield focused on efficient VLAs, alongside approaches like pruning, quantization, and distillation.

OPEN QUESTIONS:
What is the fundamental lower bound on VLA model size for different task complexities? Can knowledge distillation from large VLAs produce even better small models than training from scratch? How should we co-design robot hardware and VLA architectures for optimal efficiency? Will advances in hardware (neural accelerators, edge TPUs) make the small-model approach unnecessary?""",

    71: """STRENGTHS:
RoboMamba brings the Mamba architecture (selective state-space model) to robotic VLAs, which is an interesting architectural exploration. The key advantage over transformer-based VLAs is computational efficiency — Mamba's linear-time sequence processing is genuinely faster for long action sequences compared to transformers' quadratic attention. The paper demonstrates that the Mamba architecture can process multimodal inputs (vision, language) and generate action sequences effectively. The efficiency gains are substantial for long-horizon tasks where the action sequence length makes transformer inference prohibitively slow.

LIMITATIONS:
The empirical improvements over transformer-based VLAs are inconsistent — on many benchmarks, the Mamba-based architecture matches but does not exceed transformer performance, meaning the benefit is purely computational rather than representational. The Mamba architecture's handling of the multimodal fusion is less well-understood than transformer attention, making it harder to interpret what the model is attending to. The paper's evaluation is primarily in simulation, and it is unclear whether the efficiency gains translate to meaningful improvements on real robot hardware where the bottleneck is often sensor processing, not sequence modeling. The architecture has not been validated at the scale of large VLAs, so it is unclear whether the advantages persist as model size increases.

COMMUNITY RECEPTION:
RoboMamba received attention as part of the broader wave of interest in alternatives to transformer architectures. The efficiency claims resonated with researchers struggling to deploy large models on robots. However, the reaction was tempered by the modest empirical gains — many researchers felt that the transformer's flexibility and well-understood training dynamics outweigh Mamba's computational advantages. The work was seen as an interesting architectural exploration rather than a definitive improvement. Some researchers questioned whether the long-sequence efficiency advantage matters in practice since most robotic action sequences are short enough for transformers to handle efficiently.

OPEN QUESTIONS:
Do state-space models offer genuine advantages over transformers for robotic control beyond computational efficiency? Can Mamba-based VLAs match transformer VLAs when scaled to billions of parameters? What is the right inductive bias for processing temporal action sequences — attention, state-space models, or something else? How does the architecture choice interact with different action representations (discrete tokens vs. continuous values)?""",

    72: """STRENGTHS:
Conservative Q-Learning (CQL) is a foundational contribution to offline RL that addresses the overestimation problem in a principled way. The key insight — adding a regularizer that explicitly minimizes Q-values on out-of-distribution actions while maximizing Q-values on actions in the dataset — is theoretically elegant and produces provable lower bounds on the true Q-function. This conservatism is exactly what is needed for offline RL: the agent avoids optimistic extrapolation to unseen state-action pairs. CQL works with both SAC and DQN backbones, demonstrating generality. The theoretical analysis provides guarantees that the learned policy performs at least as well as the best policy in the dataset, under certain assumptions.

LIMITATIONS:
The conservative penalty can be overly pessimistic, particularly in regions of the state-action space with limited data coverage. This means CQL often underperforms in situations where some degree of extrapolation would be beneficial — the agent may avoid good actions simply because they were not observed often enough. The hyperparameter controlling the conservatism-performance tradeoff (alpha) requires careful tuning and is sensitive to the dataset composition. CQL scales poorly with action dimensionality because the penalty term requires sampling actions, which becomes expensive in high-dimensional continuous action spaces. The theoretical guarantees rely on assumptions (e.g., concentrability coefficients) that are hard to verify in practice.

COMMUNITY RECEPTION:
CQL was highly influential and became a standard baseline in offline RL research. The paper's theoretical rigor combined with strong empirical results set a high bar for subsequent work. It was widely adopted in D4RL benchmarks and became a go-to method for offline RL practitioners. However, practitioners found that CQL's performance is sensitive to hyperparameters and dataset quality, and that it often requires careful tuning per-domain. Some researchers felt the conservatism is too blunt an instrument and proposed more nuanced approaches (IQL, AWAC). In robotics, CQL showed promise but the conservatism sometimes prevented the robot from attempting necessary exploratory behaviors.

OPEN QUESTIONS:
Can the conservatism be made adaptive — less conservative where data is dense, more conservative where it is sparse? How does CQL perform with truly large-scale diverse datasets where the data coverage is broad but uneven? Is there a way to combine CQL's conservatism with selective optimism for promising but underexplored actions? What is the right level of conservatism for safety-critical robotic applications?""",

    73: """STRENGTHS:
Implicit Q-Learning (IQL) elegantly sidesteps the out-of-distribution action problem in offline RL by never evaluating Q-values on actions not in the dataset. The key trick — using expectile regression to approximate the maximum Q-value without actually performing the maximization — is both theoretically clean and practically effective. IQL avoids the need for importance sampling or explicit policy constraints, which makes it simpler to implement and more numerically stable than many offline RL alternatives. The method is computationally efficient and scales well. Empirical results on D4RL benchmarks are strong, often matching or exceeding CQL while being simpler to tune.

LIMITATIONS:
The expectile regression approach is an approximation of value maximization, and the quality of this approximation degrades for multimodal action distributions and when the optimal actions are far from the dataset average. IQL inherits the fundamental limitation of offline RL methods: it cannot effectively stitch together sub-trajectories from different behaviors to form better trajectories (a property sometimes called "stitching"), though it does this better than behavior cloning. The expectile parameter (tau) still requires tuning, and the best value depends on the dataset composition. The method's simplicity also means it does not explicitly model uncertainty or provide safety guarantees, which limits its use in risk-sensitive applications.

COMMUNITY RECEPTION:
IQL became one of the most popular offline RL methods due to its simplicity, stability, and strong performance. Researchers appreciated that it avoids the complex optimization issues of other offline RL methods. It was widely adopted as a baseline and is frequently used in robotic learning pipelines. Some researchers viewed IQL as evidence that offline RL does not need to be complicated — simple, well-designed algorithms can be competitive. Critics noted that IQL's advantages over CQL are often marginal and dataset-dependent. The method inspired follow-up work on simplifying offline RL further.

OPEN QUESTIONS:
Can the expectile regression approach be generalized to handle multimodal optimal action distributions? How does IQL perform as the dataset size and diversity scale up — does it converge to optimal behavior? What is the right combination of IQL with online fine-tuning for the offline-to-online RL setting? Can IQL be naturally extended to handle multi-task offline RL with shared data?""",

    74: """STRENGTHS:
Decision Transformer reframed offline RL as a sequence modeling problem, which was a conceptually influential shift. By conditioning a transformer on desired returns, past states, and past actions, the model can generate actions that achieve specified return levels at test time. This is elegant because it sidesteps the need for dynamic programming, bootstrapping, and many other complexities of traditional RL. The approach leverages the transformer architecture's known strengths in sequence modeling. The simplicity of the approach — it is essentially supervised learning on sequences with return conditioning — makes it easy to implement and understand. The paper demonstrated competitive results on D4RL benchmarks, particularly for expert-level data.

LIMITATIONS:
Decision Transformer does not perform trajectory stitching well — it cannot combine suboptimal trajectory segments to create better-than-demonstrated behavior, which is a fundamental advantage of Q-learning-based offline RL methods. The model essentially performs return-conditioned behavior cloning, meaning it can only reproduce behaviors that exist in the dataset at roughly the specified return level. With sparse rewards, the model struggles significantly because the return conditioning signal is uninformative for most of the trajectory. The approach requires knowing what return to condition on at test time, which is non-trivial for new tasks. The computational cost of the transformer for long sequences can be prohibitive for real-time control.

COMMUNITY RECEPTION:
Decision Transformer was one of the most discussed papers in RL, generating both enthusiasm and skepticism. The "RL as sequence modeling" framing was intellectually provocative and inspired a wave of follow-up work (Gato, trajectory transformers, etc.). Proponents argued it showed that the RL community was overcomplicating things. Critics, particularly from the theoretical RL community, pointed out that the inability to stitch trajectories means Decision Transformer is fundamentally less capable than proper offline RL algorithms on suboptimal data. The debate was productive and led to a clearer understanding of when sequence modeling versus dynamic programming approaches are appropriate. In robotics, the approach found moderate adoption for offline learning from demonstrations.

OPEN QUESTIONS:
Can the trajectory stitching limitation be overcome within the sequence modeling framework, or is dynamic programming fundamentally necessary? How should return conditioning work for multi-task settings where return distributions differ across tasks? Can Decision Transformer be effectively combined with online RL for continued improvement? Is there a way to handle sparse rewards without resorting to reward shaping or hindsight relabeling?""",

    75: """STRENGTHS:
This VLA survey provides a comprehensive overview of the rapidly growing field of vision-language-action models for robotics. The taxonomy organizing VLAs by architecture type (end-to-end, modular, hierarchical), training paradigm (imitation learning, RL, hybrid), and application domain (manipulation, navigation, locomotion) is well-structured and useful for newcomers. The survey covers a broad range of papers and provides clear summaries of each. The discussion of open challenges (generalization, safety, sim-to-real transfer) reflects genuine understanding of the field. The comparison tables with architecture details and reported results are practically useful.

LIMITATIONS:
The survey, like many in a fast-moving field, risks being outdated by the time of publication — several important papers were likely released during the review period. The taxonomy choices, while reasonable, impose structure that sometimes forces awkward categorizations of papers that span multiple categories. The performance comparisons across papers are presented without sufficient discussion of the incomparability of evaluation setups — different papers use different robots, tasks, and metrics, making table-based comparisons misleading. The survey does not deeply engage with negative results or limitations of the VLA paradigm itself, reading more as a cheerleading exercise than a critical analysis. The coverage of non-manipulation applications (navigation, locomotion) is notably shallower.

COMMUNITY RECEPTION:
The survey was appreciated as a useful reference for researchers entering the VLA field. The taxonomy and comparison tables were frequently referenced. However, some senior researchers noted that the survey lacks depth in its analysis — it describes what each paper does but does not synthesize insights about why certain approaches work better than others. The survey contributed to the narrative that VLAs are the dominant paradigm in robot learning, which some researchers found premature. Multiple competing surveys on similar topics (see papers #76-80) suggest that no single survey has become the definitive reference.

OPEN QUESTIONS:
What would a truly fair benchmark for comparing VLAs look like, with standardized robots, tasks, and metrics? Are VLAs the right paradigm for all robotic applications, or are there domains where alternative approaches are fundamentally better? How should surveys handle the rapid pace of publication in this area? What meta-analyses of VLA papers would be most informative for guiding future research?""",

    76: """STRENGTHS:
This survey focuses specifically on VLAs for robotic manipulation, which allows for a deeper treatment of manipulation-specific challenges compared to broader surveys. The "recipe" framing is practical — the survey is organized around design decisions that practitioners need to make (backbone selection, action representation, training data, fine-tuning strategy). The systematic comparison of action representations (discrete tokens, continuous values, diffusion-based) is particularly valuable. The paper includes practical recommendations for practitioners, which is rare in surveys.

LIMITATIONS:
The "recipe" framing implies a more prescriptive and settled understanding than the field actually has — the optimal design choices are still very much open questions, and what works depends heavily on the specific application. Some of the recommendations are based on limited evidence and may not generalize. The survey is biased toward manipulation approaches that use standard robot arms and may not adequately cover mobile manipulation or humanoid manipulation. The coverage of training data considerations, while present, does not deeply engage with the data collection bottleneck that is arguably the biggest practical challenge. Performance comparisons between methods are not always fair due to different evaluation protocols.

COMMUNITY RECEPTION:
The recipe format was appreciated by practitioners who found it more actionable than traditional surveys organized by architecture type. The practical orientation set it apart from more academic surveys. However, some researchers cautioned that the recipes might be overly simplistic and could lead to cargo-cult engineering. The survey was seen as a useful complement to the more comprehensive VLA surveys, offering practical guidance at the cost of some analytical depth.

OPEN QUESTIONS:
Can we develop principled methods for selecting VLA design choices based on task requirements, rather than empirical trial and error? What is the minimum viable recipe for getting a VLA to work on a new manipulation task? How do the recipe recommendations change as the field evolves and new approaches emerge?""",

    77: """STRENGTHS:
This comprehensive survey on pure vision-language-action models focuses specifically on approaches that directly map visual and language inputs to actions without relying on intermediate representations like keypoints or object detections. This focus is timely and reflects the trend toward end-to-end learning in robotics. The survey provides detailed architectural analyses and includes useful ablation insights compiled from multiple papers. The discussion of training strategies, including pre-training, co-training, and fine-tuning paradigms, is thorough.

LIMITATIONS:
The restriction to "pure" VLAs excludes many practical systems that use intermediate representations for good reasons (interpretability, modularity, safety). By focusing only on end-to-end approaches, the survey may give readers a skewed perspective on the state of the art. The survey does not adequately address the fundamental tension between end-to-end learning and the need for interpretable, verifiable robot behavior. Some of the categorizations and comparisons feel forced — papers do not always fit cleanly into the taxonomy. The survey could benefit from more discussion of failure modes and safety implications of pure end-to-end approaches.

COMMUNITY RECEPTION:
The survey was recognized as a thorough compilation of end-to-end VLA approaches. Researchers working on pure VLAs found it useful as a reference. However, the "pure" framing was questioned — some argued that the distinction between pure and non-pure VLAs is not well-defined and that most practical systems fall on a spectrum. The survey contributed to ongoing debates about the merits of end-to-end versus modular approaches in robotics.

OPEN QUESTIONS:
Are pure end-to-end VLAs ultimately the right approach, or will practical systems always need some structured intermediate representations? How do pure VLAs handle safety requirements that demand interpretable behavior? What theoretical guarantees can be provided for pure VLA behavior?""",

    78: """STRENGTHS:
This systematic review focuses on multimodal fusion strategies within VLAs for robotic manipulation, which is an underexplored but important topic. The analysis of different fusion approaches (early fusion, late fusion, cross-attention, tokenization) is systematic and insightful. The paper identifies patterns in which fusion strategies work best for different modality combinations and task types. The systematic review methodology (PRISMA-style) adds rigor to the literature analysis.

LIMITATIONS:
The systematic review methodology, while rigorous, can be overly mechanical — important papers may be excluded due to search term limitations or inclusion criteria. The analysis of fusion strategies is necessarily retrospective and based on published results under varying experimental conditions, making it hard to draw causal conclusions about which fusion strategy is best. The paper does not contribute new experiments or ablations that could resolve ambiguities in the literature. The focus on manipulation may miss fusion insights from other domains (autonomous driving, VLMs) that are transferable to robotics.

COMMUNITY RECEPTION:
The systematic review format was appreciated by researchers looking for structured guidance on multimodal fusion for VLAs. The paper filled a gap in the literature by focusing specifically on the fusion question rather than treating it as a secondary design choice. However, some readers found the systematic review format too rigid for such a fast-moving field and would have preferred a more opinionated analysis. The paper was more useful as a reference than as a source of actionable design guidance.

OPEN QUESTIONS:
Is there a principled way to select fusion strategies based on the modalities and tasks involved? Can we develop adaptive fusion mechanisms that learn the optimal integration strategy from data? How does the optimal fusion strategy change with model scale?""",

    79: """STRENGTHS:
This review explores the intersection of generative AI and reinforcement learning for robotics, identifying complementary strengths and potential synergies. The "duality" framing is insightful — generative models excel at representation and planning while RL excels at optimization and interaction, and combining them addresses weaknesses of each. The survey covers diffusion policies, LLM planners, world models, and RL-based fine-tuning in a unified framework. The discussion of how generative models can provide priors for RL (and vice versa) is valuable.

LIMITATIONS:
The "duality" framing, while catchy, oversimplifies the relationship — in practice, the integration of generative AI and RL is messy, with many open technical challenges around stability, sample efficiency, and credit assignment. The review is stronger on the generative AI side than the RL side, reflecting a bias toward the more trendy topic. Some important RL contributions to robotics are underrepresented. The review does not adequately address computational costs, which are a major practical barrier to combining large generative models with RL training loops. The discussion of safety and reliability of combined systems is superficial.

COMMUNITY RECEPTION:
The review was appreciated for its synthetic perspective at a time when the generative AI and RL communities are increasingly interacting. The duality framing helped researchers from both communities find common ground. However, some RL researchers felt their field was being subsumed into the generative AI narrative, and that fundamental RL contributions were being undervalued. The review contributed to productive discussion about how these paradigms should be combined in practice.

OPEN QUESTIONS:
What is the right division of labor between generative models and RL in robot learning pipelines? Can generative model priors truly replace the need for extensive RL exploration? How do we ensure that RL fine-tuning of generative models does not destroy useful pre-trained representations? What safety guarantees can be provided for systems that combine generative planning with RL execution?""",

    80: """STRENGTHS:
This survey on efficient VLAs directly addresses the elephant in the room: most VLAs are too large and slow for practical robotic deployment. The systematic coverage of efficiency techniques — pruning, quantization, knowledge distillation, efficient architectures, and hardware-aware design — is comprehensive and practically relevant. The survey includes useful benchmarks comparing inference speed and memory usage across approaches. The discussion of the efficiency-capability tradeoff frontier is informative.

LIMITATIONS:
The survey's focus on efficiency metrics (latency, FLOPs, memory) sometimes overshadows the more important question of task performance — a fast model that does not work is not useful. The efficiency landscape changes rapidly with hardware improvements, meaning some of the survey's recommendations may become obsolete as new accelerators emerge. The survey does not adequately address the question of which tasks genuinely require large models versus which can be solved with small ones — the assumption that we need to compress large models may not always hold. Some efficiency techniques are presented without sufficient discussion of their failure modes or the tasks where they degrade performance unacceptably.

COMMUNITY RECEPTION:
The survey resonated with robotics practitioners who have firsthand experience with the deployment challenges of large VLAs. The practical orientation and efficiency benchmarks were valued. However, some researchers in the foundation model community argued that efficiency concerns are premature — the field should first figure out what capabilities matter before optimizing for speed. The survey was seen as a useful counterpoint to the trend of ever-larger VLAs, advocating for practicality alongside capability.

OPEN QUESTIONS:
What is the right efficiency target for different robotic applications (latency requirements vary from 1Hz for planning to 1000Hz for force control)? Will hardware improvements make model compression unnecessary? Can we co-design VLA architectures and robot hardware for optimal efficiency? What capabilities are fundamentally lost when compressing VLAs, and which are preserved?""",

    81: """STRENGTHS:
"Towards Generalist Robots" provides a thoughtful high-level vision for the future of robot learning, arguing for general-purpose robots that can handle diverse tasks and environments. The paper synthesizes insights from foundation models, embodied AI, and traditional robotics to articulate what a generalist robot would need: broad perception, flexible manipulation, generalizable reasoning, and continuous learning. The discussion of evaluation frameworks for generalist robots is valuable — the field lacks standardized ways to measure generality. The paper identifies key research directions including data scaling, architecture design, and sim-to-real transfer.

LIMITATIONS:
The paper is primarily a vision/position paper and does not contribute new technical methods or experimental results. Many of the identified challenges (generalization, data efficiency, safety) are well-known, and the paper does not offer concrete solutions. The optimistic framing underestimates the fundamental difficulties in achieving generalist robots — the gap between current systems and true generality is enormous. The paper does not adequately engage with arguments that specialized robots may be more practical and economically viable than generalist ones. The evaluation framework discussion, while valuable, is not developed enough to be directly implementable.

COMMUNITY RECEPTION:
The paper was widely read and discussed as an articulation of the field's aspirations. Researchers appreciated the synthesis and the call for standardized evaluation. However, some found it overly optimistic and insufficiently grounded in the current technical reality. Critics argued that the "generalist robot" framing, while inspiring, may be misleading — it suggests a coherent goal when the technical challenges are disparate and may require different solutions. The paper contributed to the narrative of convergence between AI and robotics but was more inspirational than technical.

OPEN QUESTIONS:
Is a single generalist robot the right goal, or should we aim for a fleet of specialized robots that collectively cover diverse tasks? What is the minimum level of generality that would be practically useful? How should we measure progress toward generalist robots in a way that is meaningful and comparable? What are the fundamental limits of generalization in physical systems?""",

    82: """STRENGTHS:
Lynch and Park's "Modern Robotics" is an outstanding textbook that brings mathematical rigor to robot mechanics, planning, and control. The treatment of screw theory and the product of exponentials formulation is more elegant and unified than the Denavit-Hartenberg convention used in older texts. The book covers a remarkable breadth of topics — kinematics, dynamics, motion planning, trajectory optimization, and control — with consistent mathematical notation and clear pedagogical progression. The freely available course videos and software complement the text. The emphasis on geometric intuition alongside mathematical formalism makes the material accessible without sacrificing depth.

LIMITATIONS:
The screw theory approach, while elegant, has a steeper learning curve than the DH convention, which can be a barrier for students coming from more engineering-oriented backgrounds. The book's coverage of modern topics like learning-based control, tactile sensing, and human-robot interaction is limited — it is fundamentally a classical robotics text. Some practitioners find the level of mathematical abstraction excessive for practical robot programming. The coverage of real-world implementation challenges (sensor noise, actuator limitations, computational constraints) is thin compared to the theoretical treatment. The planning and control chapters do not deeply engage with the uncertainty and stochasticity inherent in real-world robotics.

COMMUNITY RECEPTION:
"Modern Robotics" is widely regarded as one of the best contemporary robotics textbooks and is used in courses at top universities worldwide. The screw theory approach has gained acceptance as a more principled alternative to DH parameters. Students and instructors appreciate the clear writing, freely available resources, and the book's comprehensive scope. However, some instructors still prefer Siciliano et al. or Craig for courses focused on practical robot programming, finding Lynch and Park too mathematically focused for applied courses. The book established a new standard for mathematical rigor in robotics education.

OPEN QUESTIONS:
How should classical robotics curricula be updated to integrate modern learning-based approaches while maintaining mathematical foundations? Is screw theory the right mathematical framework for soft robots and continuum manipulators? How do the control-theoretic approaches in the book connect to modern VLA-based control? What supplementary material is needed to bridge the gap between the book's theoretical treatment and modern robot learning research?""",

    83: """STRENGTHS:
Russ Tedrake's "Underactuated Robotics" course notes are a masterful treatment of dynamics and control for systems where you cannot simply command arbitrary joint torques. The focus on underactuation is brilliant because it captures the reality of many important robotic systems — legged robots, flying robots, swimming robots, and manipulators interacting with the environment all involve underactuation. The mathematical treatment using tools from nonlinear dynamics, Lyapunov analysis, optimization, and computational geometry is deep and rigorous. The living document format, continually updated with new research, keeps it current. The integration of Drake software for computational examples is excellent for learning.

LIMITATIONS:
The material is advanced and assumes strong backgrounds in linear algebra, optimization, and dynamical systems, making it inaccessible to many robotics students, particularly those from more applied backgrounds. The focus on model-based approaches and mathematical optimization means the treatment of learning-based control is relatively thin, though recent updates have begun to address this. Some of the chapters feel more like research notes than polished textbook material, with varying levels of pedagogical scaffolding. The Drake software, while powerful, has a steep learning curve. The scope is necessarily limited — deformable objects, contact-rich manipulation, and multi-robot systems receive less attention.

COMMUNITY RECEPTION:
Tedrake's notes are revered in the robotics and control community, particularly by students and researchers working on locomotion, manipulation, and planning. The freely available format democratized access to material that was previously only available in advanced graduate courses. Researchers appreciate the depth and mathematical rigor, and the notes have influenced how an entire generation thinks about robot control. Some practitioners find the material overly theoretical for their needs, but acknowledge its importance for foundational understanding. The continual updates keep it relevant as the field evolves.

OPEN QUESTIONS:
How should the classical control-theoretic perspective presented here be integrated with modern learning-based approaches? Can the optimization-based control methods scale to the complexity of real-world unstructured environments? What is the right role for model-based control in an era of end-to-end learning? How do we teach underactuated robotics concepts to students who primarily work with data-driven methods?""",

    84: """STRENGTHS:
Rich Sutton's "The Bitter Lesson" is one of the most important essays in AI, arguing that the history of AI research shows that general methods leveraging computation (search and learning) ultimately outperform approaches that attempt to encode human knowledge. The argument is supported by compelling examples from chess, computer vision, speech recognition, and Go, where hand-crafted approaches were eventually surpassed by general learning methods as compute scaled up. The essay is concise, provocative, and forces researchers to confront uncomfortable truths about the trajectory of the field. The core insight — that human knowledge is better used to design general learning algorithms than to be directly encoded into systems — has profound implications for how we conduct research.

LIMITATIONS:
The argument, while compelling, is overly reductive and ignores critical nuances. In robotics specifically, data is expensive and dangerous to collect, which fundamentally changes the compute-scaling equation — you cannot simply throw more data at a robot learning problem the way you can at language or vision. The essay ignores the role of inductive biases, which are essential for sample efficiency and are themselves a form of leveraging human knowledge without hard-coding solutions. The examples cited (chess, Go, speech) all involve domains where simulation or data collection is cheap, which is not the case for physical robots. The essay also does not address safety — in safety-critical systems, pure scaling without structure is irresponsible. Furthermore, the "bitter lesson" may be a selection bias: we remember the successes of scaling but not the many domains where human-engineered solutions remain superior.

COMMUNITY RECEPTION:
The essay is widely cited and has become a touchstone in debates about research methodology. Foundation model advocates frequently invoke it to justify scaling approaches. In the robotics community, the reception is more nuanced — many researchers agree with the general direction but argue that robotics is different because of the data bottleneck and safety requirements. The essay has been criticized for potentially discouraging research on sample efficiency, safety, and interpretability by framing such work as fighting against the tide of history. Some prominent researchers (e.g., Yann LeCun, Rodney Brooks) have pushed back, arguing that architectural innovations and inductive biases have been essential to progress, not just scaling.

OPEN QUESTIONS:
Does the bitter lesson apply to robotics, where data collection is fundamentally more expensive and risky than in digital domains? What is the role of inductive biases and architectural innovations if the bitter lesson is true — are they merely temporary scaffolding or essential for certain problem types? Can we reconcile the bitter lesson with the need for sample efficiency in physical systems? Is there a "sweet spot" that combines general learning methods with just enough structure to be practical for robotics?""",
}


def seed():
    admin = get_admin_client()
    for number, review in REVIEWS.items():
        admin.table("papers").update({"peer_reviews": review}).eq("number", number).execute()
        print(f"  Seeded peer review for paper #{number}")


if __name__ == "__main__":
    seed()
    print("Done!")
